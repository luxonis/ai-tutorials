{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Object Detection Model\n",
    "\n",
    "## üåü Overview\n",
    "In this tutorial we'll go through the process of training a custom object detection model. We'll first create a dataset, setup the training configuration and then use it to train our own NN model. We'll also validate the performance of our model, export it and make it ready for a deployment on a Luxonis device.\n",
    "\n",
    "## üìú Table of Contents\n",
    "- [üõ†Ô∏è Installation](#Ô∏è-installation)\n",
    "- [üóÉÔ∏è Data Preparation](#Ô∏è-data-preparation)\n",
    "    - [üßê Generating Object Detection Annotation](#-generating-object-detection-annotation)\n",
    "    - [üíæ LuxonisDataset](#-luxonisdataset)\n",
    "- [üèãÔ∏è‚Äç‚ôÇÔ∏è Training](#Ô∏èÔ∏è-training)\n",
    "    - [‚öôÔ∏è Configuration](#Ô∏è-configuration)\n",
    "    - [ü¶æ Train](#-train)\n",
    "- [‚úç Test](#-test)\n",
    "    - [üß† Infer](#-infer)\n",
    "- [üóÇÔ∏è Export and Archive](#Ô∏è-export-and-archive)\n",
    "- [ü§ñ Deploy](#-deploy)\n",
    "- [üì∑ DepthAI Script](#-depthai-script)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main focus of this tutorial is using [`LuxonisTrain`](https://github.com/luxonis/luxonis-train) together with [`DataDreamer`](https://github.com/luxonis/datadreamer). [`LuxonisTrain`](https://github.com/luxonis/luxonis-train) is a user-friendly tool designed to streamline the training of deep learning models, especially for edge devices. [`DataDreamer`](https://github.com/luxonis/datadreamer) is an advanced toolkit for generating synthetic datasets and annotating images using the latest foundational models. We'll download our images from [`Kaggle`](https://www.kaggle.com/), generate annotations and store it in `LuxonisDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q kaggle datadreamer@git+https://github.com/luxonis/datadreamer.git@dev luxonis-train@git+https://github.com/luxonis/luxonis-train.git@main luxonis-ml==0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÉÔ∏è Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to download and prepare our dataset. For this example, we'll use a publicly available dataset from Kaggle called [`Cats and Dogs 40`](https://www.kaggle.com/datasets/stefancomanita/cats-and-dogs-40). This dataset is originally an image classification dataset. However, we will utilize the aforementioned [`DataDreamer`](https://github.com/luxonis/datadreamer) toolkit to generate object detection annotation for the images. Therefore, our task is to train a model that is able to detect cats and dogs. \n",
    "\n",
    "To download the dataset, we'll run this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/stefancomanita/cats-and-dogs-40\n",
      "License(s): CC0-1.0\n",
      "Downloading cats-and-dogs-40.zip to data\n",
      "  0%|                                                | 0.00/445k [00:00<?, ?B/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 445k/445k [00:00<00:00, 18.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# !rm -r ./data/catsAndDogs40/ # Run if you want to re-download the dataset\n",
    "!kaggle datasets download -d stefancomanita/cats-and-dogs-40 -p data --unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll move images to one place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "!rm -r catdogs_dataset/\n",
    "!mkdir catdogs_dataset\n",
    "!for file in ./data/catsAndDogs40/train/cat/*.jpg; do mv \"$file\" \"${file%.*}_train_cat.${file##*.}\"; done && cp ./data/catsAndDogs40/train/cat/*.jpg ./catdogs_dataset/\n",
    "!for file in ./data/catsAndDogs40/train/dog/*.jpg; do mv \"$file\" \"${file%.*}_train_dog.${file##*.}\"; done && cp ./data/catsAndDogs40/train/dog/*.jpg ./catdogs_dataset/\n",
    "!for file in ./data/catsAndDogs40/test/cat/*.jpg; do mv \"$file\" \"${file%.*}_test_cat.${file##*.}\"; done && cp ./data/catsAndDogs40/test/cat/*.jpg ./catdogs_dataset/\n",
    "!for file in ./data/catsAndDogs40/test/dog/*.jpg; do mv \"$file\" \"${file%.*}_test_dog.${file##*.}\"; done && cp ./data/catsAndDogs40/test/dog/*.jpg ./catdogs_dataset/\n",
    "!ls ./catdogs_dataset/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßê Generating Object Detection Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use the [`DataDreamer`](https://github.com/luxonis/datadreamer) toolkit to annotate the `80` images. The toolkit will detect cats and dogs in each image and generate bounding boxes for each animal. Furthermore, using `--dataset_format luxonis-dataset` will convert the data to the correct format: `LuxonisDataset`, which we need for the training.\n",
    "\n",
    "To discover all available DataDreamer arguments, please refer to [here](https://github.com/luxonis/datadreamer?tab=readme-ov-file#-main-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-10 23:15:05.452583: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-10 23:15:05.509911: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-10 23:15:05.509964: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-10 23:15:05.511762: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-10 23:15:05.520739: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-10 23:15:06.488422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "\u001b[32mINFO    \u001b[0m Profanity filter is checking classes: \u001b[1m[\u001b[0m\u001b[32m'cat'\u001b[0m,   \u001b]8;id=112931;file:///opt/conda/lib/python3.11/site-packages/datadreamer/prompt_generation/profanity_filter.py\u001b\\\u001b[2mprofanity_filter.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=879234;file:///opt/conda/lib/python3.11/site-packages/datadreamer/prompt_generation/profanity_filter.py#170\u001b\\\u001b[2m170\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[32m'dog'\u001b[0m\u001b[1m]\u001b[0m                                          \u001b[2m                       \u001b[0m\n",
      "Generating synonyms: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.50s/it]\n",
      "\u001b[32mINFO    \u001b[0m Initializing OWLv2 large model\u001b[33m...\u001b[0m                 \u001b]8;id=348334;file:///opt/conda/lib/python3.11/site-packages/datadreamer/dataset_annotation/owlv2_annotator.py\u001b\\\u001b[2mowlv2_annotator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=357352;file:///opt/conda/lib/python3.11/site-packages/datadreamer/dataset_annotation/owlv2_annotator.py#60\u001b\\\u001b[2m60\u001b[0m\u001b]8;;\u001b\\\n",
      "Annotating images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [02:07<00:00,  1.59s/it]\n",
      "\u001b[32mINFO    \u001b[0m Deleted dataset cat_dogs_dataset                 \u001b]8;id=350010;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py\u001b\\\u001b[2mluxonis_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735775;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py#377\u001b\\\u001b[2m377\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[32mINFO    \u001b[0m Using local dataset                    \u001b]8;id=91869;file:///opt/conda/lib/python3.11/site-packages/datadreamer/utils/luxonis_dataset_converter.py\u001b\\\u001b[2mluxonis_dataset_converter.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=921310;file:///opt/conda/lib/python3.11/site-packages/datadreamer/utils/luxonis_dataset_converter.py#160\u001b\\\u001b[2m160\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[32mINFO    \u001b[0m Class \u001b[3;31mdog\u001b[0m\u001b[39;49m doesn't belong to any existing task. \u001b[0m  \u001b]8;id=767598;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py\u001b\\\u001b[2mluxonis_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=470099;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py#403\u001b\\\u001b[2m403\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[39;49mAutogenerated task \u001b[0m\u001b[3;35;49mclassification\u001b[0m\u001b[39;49m will be used.\u001b[0m  \u001b[2m                      \u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m Class \u001b[3;31mdog\u001b[0m\u001b[39;49m doesn't belong to any existing task. \u001b[0m  \u001b]8;id=699545;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py\u001b\\\u001b[2mluxonis_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=149081;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py#403\u001b\\\u001b[2m403\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[39;49mAutogenerated task \u001b[0m\u001b[3;35;49mboundingbox\u001b[0m\u001b[39;49m will be used.\u001b[0m     \u001b[2m                      \u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m Class \u001b[3;31mcat\u001b[0m\u001b[39;49m doesn't belong to any existing task. \u001b[0m  \u001b]8;id=305976;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py\u001b\\\u001b[2mluxonis_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=955410;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py#403\u001b\\\u001b[2m403\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[39;49mAutogenerated task \u001b[0m\u001b[3;35;49mclassification\u001b[0m\u001b[39;49m will be used.\u001b[0m  \u001b[2m                      \u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m Class \u001b[3;31mcat\u001b[0m\u001b[39;49m doesn't belong to any existing task. \u001b[0m  \u001b]8;id=492089;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py\u001b\\\u001b[2mluxonis_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=878536;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py#403\u001b\\\u001b[2m403\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[39;49mAutogenerated task \u001b[0m\u001b[3;35;49mboundingbox\u001b[0m\u001b[39;49m will be used.\u001b[0m     \u001b[2m                      \u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m Generating UUIDs\u001b[33m...\u001b[0m                              \u001b]8;id=840430;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py\u001b\\\u001b[2mluxonis_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=506421;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py#482\u001b\\\u001b[2m482\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[32mINFO    \u001b[0m Checking arrays\u001b[33m...\u001b[0m                               \u001b]8;id=592250;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py\u001b\\\u001b[2mluxonis_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=848652;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py#442\u001b\\\u001b[2m442\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2K\u001b[35mProcessing arrays...\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m188/188\u001b[0m \u001b[36m0:00:00\u001b[0m0m\n",
      "\u001b[?25h\u001b[32mINFO    \u001b[0m Saving annotations\u001b[33m...\u001b[0m                            \u001b]8;id=677542;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py\u001b\\\u001b[2mluxonis_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=537659;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py#501\u001b\\\u001b[2m501\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2K\u001b[35mProcessing data...\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m188/188\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[32mINFO    \u001b[0m Detected new classes for task classification:    \u001b]8;id=699041;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py\u001b\\\u001b[2mluxonis_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=625480;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py#588\u001b\\\u001b[2m588\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[1m[\u001b[0m\u001b[32m'dog'\u001b[0m, \u001b[32m'cat'\u001b[0m\u001b[1m]\u001b[0m                                   \u001b[2m                      \u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m Detected new classes for task boundingbox:       \u001b]8;id=700941;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py\u001b\\\u001b[2mluxonis_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=439873;file:///opt/conda/lib/python3.11/site-packages/luxonis_ml/data/datasets/luxonis_dataset.py#588\u001b\\\u001b[2m588\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[1m[\u001b[0m\u001b[32m'dog'\u001b[0m, \u001b[32m'cat'\u001b[0m\u001b[1m]\u001b[0m                                   \u001b[2m                      \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!datadreamer --save_dir catdogs_dataset \\\n",
    "            --class_names cat dog \\\n",
    "            --prompts_number 80 \\\n",
    "            --num_objects_range 1 1 \\\n",
    "            --synonym_generator wordnet \\\n",
    "            --image_annotator owlv2 \\\n",
    "            --annotator_size large \\\n",
    "            --annotate_only \\\n",
    "            --disable_lm_filter \\\n",
    "            --conf_threshold 0.4 \\\n",
    "            --annotation_iou_threshold 0.5 \\\n",
    "            --dataset_name cat_dogs_dataset \\\n",
    "            --dataset_format luxonis-dataset \\\n",
    "            --split_ratios 0.7 0.15 0.15 \\\n",
    "            --seed 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize the generated bounding boxes for one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='catdogs_dataset/bboxes_visualization/bbox_5.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ LuxonisDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the `DataDreamer`, our dataset is already in the correct format: `LuxonisDataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that the data is correctly loaded and split into subsets we can check the dataset's information and visualizations of the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Dataset Info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n",
      "‚îÇ \u001b[1;35mName: \u001b[0m\u001b[36mcat_dogs_dataset\u001b[0m           ‚îÇ\n",
      "‚îÇ                                  ‚îÇ\n",
      "‚îÇ ‚ï≠‚îÄ Split Sizes ‚îÄ‚ïÆ                ‚îÇ\n",
      "‚îÇ ‚îÇ \u001b[1;35mtrain: \u001b[0m\u001b[36m56\u001b[0m     ‚îÇ                ‚îÇ\n",
      "‚îÇ ‚îÇ \u001b[1;35mval: \u001b[0m\u001b[36m12\u001b[0m       ‚îÇ                ‚îÇ\n",
      "‚îÇ ‚îÇ \u001b[1;35mtest: \u001b[0m\u001b[36m12\u001b[0m      ‚îÇ                ‚îÇ\n",
      "‚îÇ ‚îÇ \u001b[92m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m ‚îÇ                ‚îÇ\n",
      "‚îÇ ‚îÇ \u001b[1;35mTotal: \u001b[0m\u001b[36m80\u001b[0m     ‚îÇ                ‚îÇ\n",
      "‚îÇ ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ                ‚îÇ\n",
      "‚îÇ \u001b[3m            Classes             \u001b[0m ‚îÇ\n",
      "‚îÇ ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ ‚îÇ\n",
      "‚îÇ ‚îÇ\u001b[1;3;35m \u001b[0m\u001b[1;3;35mTask          \u001b[0m\u001b[1;3;35m \u001b[0m‚îÇ\u001b[1;3;35m \u001b[0m\u001b[1;3;35mClass Names\u001b[0m\u001b[1;3;35m \u001b[0m‚îÇ ‚îÇ\n",
      "‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ\n",
      "‚îÇ ‚îÇ\u001b[33m \u001b[0m\u001b[33mclassification\u001b[0m\u001b[33m \u001b[0m‚îÇ\u001b[33m \u001b[0m\u001b[33mcat, dog   \u001b[0m\u001b[33m \u001b[0m‚îÇ ‚îÇ\n",
      "‚îÇ ‚îÇ\u001b[36m \u001b[0m\u001b[36mboundingbox   \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[36m \u001b[0m\u001b[36mcat, dog   \u001b[0m\u001b[36m \u001b[0m‚îÇ ‚îÇ\n",
      "‚îÇ ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ ‚îÇ\n",
      "‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n"
     ]
    }
   ],
   "source": [
    "!luxonis_ml data info cat_dogs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!luxonis_ml data inspect cat_dogs_dataset # NOTE: If you are on Google Colab this command will not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÇÔ∏è Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have prepared the dataset, and we are almost ready for the actual training. The last step is just to set up our training configuration file. The whole training process in `LuxonisTrain` doesn't require any coding. We advise you to take one of the base configuration files from [here](https://github.com/luxonis/luxonis-train/tree/main/configs) depending on the task and then edit you to fit your needs.\n",
    "\n",
    "In our case we are training an object detection and thus we'll take a [`detection_light_model.yaml`](https://github.com/luxonis/luxonis-train/blob/main/configs/detection_light_model.yaml) as a starting point, which downloads a pretrained COCO weights and so it is ideal for fine tuning. There are a lot of parameters that we can change, and we advise you to go through the [`documentation`](https://github.com/luxonis/luxonis-train/blob/main/configs/README.md) to find all of them. In this tutorial, we'll only go through some basic ones to get you started on your journey.\n",
    "\n",
    "#### Model\n",
    "In this section, you can either choose one of the predefined architectures (all of them listed [here](https://github.com/luxonis/luxonis-train/tree/main/luxonis_train/config/predefined_models)) or create a completely custom neural network by connection different nodes, losses, metrics, and visualizers together. We'll go with the predefined `DetectionModel`.\n",
    "\n",
    "#### Loader\n",
    "This section of the config referes to the data loading. You can either set up your custom Loader or use the default one with the `LuxonisDataset`. In our case, we'll go with the second option, and all we need to do is to set `dataset_name` to `cat_dogs_dataset`.\n",
    "\n",
    "#### Trainer\n",
    "In this section, we can set up everything connected to actual training. You can change preprocessing, batch size, epochs, add callbacks, augmentations, change optimizers, schedulers and many more. Please refer to the [full documentation](https://github.com/luxonis/luxonis-train/tree/main/configs). \n",
    "\n",
    "**Augmentations**\n",
    "In our case, we'll leave most of the things as they are; the only change will be adding some augmentations. We use [`Albumentations`](https://albumentations.ai/) for our augmentations with the addition of some custom ones like Mosaic4 and MixUp. You can use [this demo](https://demo.albumentations.ai/) to experiment and find those that work for your specific training run. We can add some Affine transforms; for this specific training run, we'll add some Affine transforms, HorizontalFlip, ColorJitter, and Sharpen, but feel free to edit this.\n",
    "\n",
    "**Callbacks**\n",
    "Callbacks are very helpful when we want to merge more functionalities into a single training run. For example, we want first to train the model then evaluate it on test subset, export it and create an archive. All of these steps can be defined through the config and done by a single call. For the purpose of a nicer explanation we won't be using them in this tutorial but feel free to set them up on your own. You can check out all the available callbacks [here](https://github.com/luxonis/luxonis-train/tree/main/luxonis_train/callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a starting point for your config. As mentioned we already made some changes to it so it works with this tutorial (change of model name, dataset name and addition of augmentations) but feel free to edit it further and make it your own. When you are done editing you can just execute the cell and the file will be written and ready to use.\n",
    "\n",
    "**Note**: In case you don't have enough compute on your machine you can either use [Google Colab](https://colab.research.google.com/) (with GPU enabled) or you can try lowering number of epochs and/or batch size but in that case performance might drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cat_dog_detection_config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile cat_dog_detection_config.yaml\n",
    "model:\n",
    "  name: cat_dog_detection_model\n",
    "  predefined_model:\n",
    "    name: DetectionModel\n",
    "    params:\n",
    "      variant: light\n",
    "\n",
    "loader:\n",
    "  params:\n",
    "    dataset_name: cat_dogs_dataset\n",
    "\n",
    "trainer:\n",
    "  preprocessing:\n",
    "    train_image_size: [320, 320]\n",
    "    keep_aspect_ratio: true\n",
    "    normalize:\n",
    "      active: true\n",
    "\n",
    "    augmentations:\n",
    "      - name: Affine\n",
    "        params:\n",
    "          scale: [0.7, 1.7]\n",
    "          rotate: 20\n",
    "          shear: 5\n",
    "          p: 0.3\n",
    "      - name: HorizontalFlip\n",
    "        params:\n",
    "          p: 0.3\n",
    "      - name: ColorJitter\n",
    "        params:\n",
    "          brightness: [0.8, 1.2]\n",
    "          contrast: [0.8, 1.2]\n",
    "          saturation: [0.8, 1.2]\n",
    "          hue: 0\n",
    "          p: 0.2\n",
    "      - name: Sharpen\n",
    "        params:\n",
    "          p: 0.3\n",
    "\n",
    "  batch_size: 8\n",
    "  epochs: &epochs 50\n",
    "  n_workers: 8\n",
    "  validation_interval: 10\n",
    "  n_log_images: 8\n",
    "\n",
    "  optimizer:\n",
    "    name: SGD\n",
    "    params:\n",
    "      lr: 0.0002           \n",
    "      momentum: 0.843      \n",
    "      weight_decay: 0.00036 \n",
    "      dampening: 0.0        \n",
    "      nesterov: true    \n",
    "\n",
    "  scheduler:\n",
    "    name: CosineAnnealingLR\n",
    "    params:\n",
    "      T_max: *epochs         \n",
    "      eta_min: 0.00001\n",
    "\n",
    "  callbacks:\n",
    "    - name: EMACallback\n",
    "      params:\n",
    "        decay: 0.9999 \n",
    "        use_dynamic_decay: True \n",
    "        decay_tau: 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶æ Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the training we just need to initialize the `LuxonisModel`, pass it the path to the configuration file and call the `train()` method on it.\n",
    "\n",
    "**Note**: LuxonisTrain also supports all these commands through usage of its CLI ([docs here](https://github.com/luxonis/luxonis-train/tree/main?tab=readme-ov-file#-cli)), no code required. We won't use them for tutorial purposes but when you do it yourself feel free to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luxonis_train import LuxonisModel\n",
    "\n",
    "config_path = \"cat_dog_detection_config.yaml\"\n",
    "\n",
    "luxonis_model = LuxonisModel(config_path)\n",
    "luxonis_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LuxonisTrain` already implements automatic tracking of our training runs. By default, `Tensorboard` is used, and to look at the losses, metrics, and visualizations during training, we can inspect the logs. If you check the `output` folder, you'll see that every run creates a new directory in it, and each run also has its own training logs in the `./output/tensorboard_logs` where the name of the folder matches the run's name. To make all the subsequent commands work automatically, please set the name of your run below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = \"79-blush-viper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output/tensorboard_logs/{RUN_NAME}/ # TODO: Change the name of the training run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úç Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a model that we are happy with, that seems to perform well on the validation set. The next step is to check its performance on the testing set. This is a collection of images that we've kept hidden from the model so far and should be only used to objectively evaluate if the model is good or not. Since this is an object detection task we use mean average precision metric to quantitatively check the model performance.\n",
    "\n",
    "If you check out ran directory you'll see two folders inside: `best_val_metric` and `min_val_loss`. Both of these have checkpoint files that were generated during trainig based on best validation metric performance and minimal validation loss respectively. For evaluation we'll want to use one of these checkpoints, we recommend you use one that has lowest validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Loaded checkpoint from                                                            <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">luxonis_lightning.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#937\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">937</span></a>\n",
       "         <span style=\"color: #800080; text-decoration-color: #800080\">/home/jovyan/output/79-blush-viper/min_val_loss/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">cat_dog_detection_model_loss</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>72 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>\n",
       "         17_49.ckpt.                                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Loaded checkpoint from                                                            \u001b]8;id=590588;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\u001b\\\u001b[2mluxonis_lightning.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=833434;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#937\u001b\\\u001b[2m937\u001b[0m\u001b]8;;\u001b\\\n",
       "         \u001b[35m/home/jovyan/output/79-blush-viper/min_val_loss/\u001b[0m\u001b[95mcat_dog_detection_model_loss\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0m72 \u001b[2m                        \u001b[0m\n",
       "         17_49.ckpt.                                                                       \u001b[2m                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> The following callbacks returned in `LightningModule.configure_callbacks` will override    <a href=\"file:///opt/conda/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#64\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">64</span></a>\n",
       "         existing callbacks passed to Trainer: EMACallback, ModelCheckpoint, RichModelSummary       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m The following callbacks returned in `LightningModule.configure_callbacks` will override    \u001b]8;id=863017;file:///opt/conda/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=131333;file:///opt/conda/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#64\u001b\\\u001b[2m64\u001b[0m\u001b]8;;\u001b\\\n",
       "         existing callbacks passed to Trainer: EMACallback, ModelCheckpoint, RichModelSummary       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352aed178b254a209329456d2001a60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Computing metrics on test subset <span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                              <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">luxonis_lightning.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#785\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">785</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Computing metrics on test subset \u001b[33m...\u001b[0m                                              \u001b]8;id=135393;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\u001b\\\u001b[2mluxonis_lightning.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=24954;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#785\u001b\\\u001b[2m785\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Metrics computed.                                                                 <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">luxonis_lightning.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#787\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">787</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Metrics computed.                                                                 \u001b]8;id=158226;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\u001b\\\u001b[2mluxonis_lightning.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=943289;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#787\u001b\\\u001b[2m787\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Test loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1702</span>                                                                 <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">luxonis_lightning.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#992\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">992</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Test loss: \u001b[1;36m1.1702\u001b[0m                                                                 \u001b]8;id=270508;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\u001b\\\u001b[2mluxonis_lightning.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=721017;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#992\u001b\\\u001b[2m992\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span>Test<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \u001b[0mTest\u001b[1;35m ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Loss:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">1.1702080368995667</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLoss:\u001b[0m \u001b[1;37m1.1702080368995667\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Metrics:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mMetrics:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">         EfficientBBoxHead-boundingbox         </span>\n",
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                             </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Value    </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> MeanAveragePrecision-boundingbox </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 0.83024  </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> map_50                           </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 0.93564  </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> map_75                           </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 0.93564  </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> map_small                        </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> -1.00000 </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> map_medium                       </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 0.00000  </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> map_large                        </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 0.88727  </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> mar_1                            </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 0.77500  </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> mar_10                           </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 0.85000  </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> mar_100                          </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 0.85000  </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> mar_small                        </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> -1.00000 </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> mar_medium                       </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 0.00000  </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> mar_large                        </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 0.90714  </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> f1_small                         </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> -1.00000 </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> f1_medium                        </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> nan      </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\"> f1_large                         </span>‚îÇ<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 0.89710  </span>‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m         EfficientBBoxHead-boundingbox         \u001b[0m\n",
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mName                            \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mValue   \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mMeanAveragePrecision-boundingbox\u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m0.83024 \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mmap_50                          \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m0.93564 \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mmap_75                          \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m0.93564 \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mmap_small                       \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m-1.00000\u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mmap_medium                      \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m0.00000 \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mmap_large                       \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m0.88727 \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mmar_1                           \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m0.77500 \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mmar_10                          \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m0.85000 \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mmar_100                         \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m0.85000 \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mmar_small                       \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m-1.00000\u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mmar_medium                      \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m0.00000 \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mmar_large                       \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m0.90714 \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mf1_small                        \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m-1.00000\u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mf1_medium                       \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37mnan     \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[35m \u001b[0m\u001b[35mf1_large                        \u001b[0m\u001b[35m \u001b[0m‚îÇ\u001b[37m \u001b[0m\u001b[37m0.89710 \u001b[0m\u001b[37m \u001b[0m‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Test main metric                                                                 <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">luxonis_lightning.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#1001\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1001</span></a>\n",
       "         <span style=\"font-weight: bold\">(</span>EfficientBBoxHead-boundingbox/MeanAveragePrecision-boundingbox<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8302</span>         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Test main metric                                                                 \u001b]8;id=236797;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\u001b\\\u001b[2mluxonis_lightning.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=655870;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#1001\u001b\\\u001b[2m1001\u001b[0m\u001b]8;;\u001b\\\n",
       "         \u001b[1m(\u001b[0mEfficientBBoxHead-boundingbox/MeanAveragePrecision-boundingbox\u001b[1m)\u001b[0m: \u001b[1;36m0.8302\u001b[0m         \u001b[2m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\">                      Test metric                       </span>‚îÉ<span style=\"font-weight: bold\">                      DataLoader 0                      </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">                       test/loss                        </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   1.1702079772949219                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\"> test/loss/EfficientBBoxHead-boundingbox/AdaptiveDetec‚Ä¶ </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   1.1702079772949219                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\"> test/loss/EfficientBBoxHead-boundingbox/AdaptiveDetec‚Ä¶ </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   0.9317578077316284                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\"> test/loss/EfficientBBoxHead-boundingbox/AdaptiveDetec‚Ä¶ </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                  0.09538006782531738                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\"> test/metric/EfficientBBoxHead-boundingbox/MeanAverage‚Ä¶ </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   0.8302392959594727                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">   test/metric/EfficientBBoxHead-boundingbox/f1_large   </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   0.8970958590507507                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">  test/metric/EfficientBBoxHead-boundingbox/f1_medium   </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                          nan                           </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">   test/metric/EfficientBBoxHead-boundingbox/f1_small   </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                          -1.0                          </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">    test/metric/EfficientBBoxHead-boundingbox/map_50    </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   0.9356435537338257                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">    test/metric/EfficientBBoxHead-boundingbox/map_75    </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   0.9356435537338257                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">  test/metric/EfficientBBoxHead-boundingbox/map_large   </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   0.8872689604759216                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">  test/metric/EfficientBBoxHead-boundingbox/map_medium  </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                          0.0                           </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">  test/metric/EfficientBBoxHead-boundingbox/map_small   </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                          -1.0                          </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">    test/metric/EfficientBBoxHead-boundingbox/mar_1     </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   0.7749999761581421                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">    test/metric/EfficientBBoxHead-boundingbox/mar_10    </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   0.8500000238418579                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">   test/metric/EfficientBBoxHead-boundingbox/mar_100    </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   0.8500000238418579                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">  test/metric/EfficientBBoxHead-boundingbox/mar_large   </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                   0.9071428775787354                   </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">  test/metric/EfficientBBoxHead-boundingbox/mar_medium  </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                          0.0                           </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">  test/metric/EfficientBBoxHead-boundingbox/mar_small   </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">                          -1.0                          </span>‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1m                     Test metric                      \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m                     DataLoader 0                     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m                      test/loss                       \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  1.1702079772949219                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36mtest/loss/EfficientBBoxHead-boundingbox/AdaptiveDetec‚Ä¶\u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  1.1702079772949219                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36mtest/loss/EfficientBBoxHead-boundingbox/AdaptiveDetec‚Ä¶\u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  0.9317578077316284                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36mtest/loss/EfficientBBoxHead-boundingbox/AdaptiveDetec‚Ä¶\u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                 0.09538006782531738                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36mtest/metric/EfficientBBoxHead-boundingbox/MeanAverage‚Ä¶\u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  0.8302392959594727                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m  test/metric/EfficientBBoxHead-boundingbox/f1_large  \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  0.8970958590507507                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m test/metric/EfficientBBoxHead-boundingbox/f1_medium  \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                         nan                          \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m  test/metric/EfficientBBoxHead-boundingbox/f1_small  \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                         -1.0                         \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m   test/metric/EfficientBBoxHead-boundingbox/map_50   \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  0.9356435537338257                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m   test/metric/EfficientBBoxHead-boundingbox/map_75   \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  0.9356435537338257                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m test/metric/EfficientBBoxHead-boundingbox/map_large  \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  0.8872689604759216                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m test/metric/EfficientBBoxHead-boundingbox/map_medium \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                         0.0                          \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m test/metric/EfficientBBoxHead-boundingbox/map_small  \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                         -1.0                         \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m   test/metric/EfficientBBoxHead-boundingbox/mar_1    \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  0.7749999761581421                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m   test/metric/EfficientBBoxHead-boundingbox/mar_10   \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  0.8500000238418579                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m  test/metric/EfficientBBoxHead-boundingbox/mar_100   \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  0.8500000238418579                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m test/metric/EfficientBBoxHead-boundingbox/mar_large  \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                  0.9071428775787354                  \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m test/metric/EfficientBBoxHead-boundingbox/mar_medium \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                         0.0                          \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m test/metric/EfficientBBoxHead-boundingbox/mar_small  \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m                         -1.0                         \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = luxonis_model.get_min_loss_checkpoint_path() # gets checkpoint where validation loss was the lowest\n",
    "# weights = luxonis_model.get_best_metric_checkpoint_path() # gets checkpoint where validation metric was the highest\n",
    "\n",
    "metrics = luxonis_model.test(view=\"test\", weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, we also want to check the qualitative performance of our model, i.e., how well it visually predicts on the test images. This is called inference, and we can perform it either on one of the views (e.g., test) or a random image, directory of images, or whole video (for more details, refer to the [docs](https://github.com/luxonis/luxonis-train/tree/main?tab=readme-ov-file#inference)). In our case, we'll infer or test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Loaded checkpoint from                                                            <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">luxonis_lightning.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#937\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">937</span></a>\n",
       "         <span style=\"color: #800080; text-decoration-color: #800080\">/home/jovyan/output/79-blush-viper/min_val_loss/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">cat_dog_detection_model_loss</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>72 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>\n",
       "         17_49.ckpt.                                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Loaded checkpoint from                                                            \u001b]8;id=5859;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\u001b\\\u001b[2mluxonis_lightning.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=567578;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#937\u001b\\\u001b[2m937\u001b[0m\u001b]8;;\u001b\\\n",
       "         \u001b[35m/home/jovyan/output/79-blush-viper/min_val_loss/\u001b[0m\u001b[95mcat_dog_detection_model_loss\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0m72 \u001b[2m                        \u001b[0m\n",
       "         17_49.ckpt.                                                                       \u001b[2m                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> The following callbacks returned in `LightningModule.configure_callbacks` will override    <a href=\"file:///opt/conda/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#64\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">64</span></a>\n",
       "         existing callbacks passed to Trainer: EMACallback, ModelCheckpoint, RichModelSummary       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m The following callbacks returned in `LightningModule.configure_callbacks` will override    \u001b]8;id=767927;file:///opt/conda/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=379852;file:///opt/conda/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py#64\u001b\\\u001b[2m64\u001b[0m\u001b]8;;\u001b\\\n",
       "         existing callbacks passed to Trainer: EMACallback, ModelCheckpoint, RichModelSummary       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2199f66d3724a12b8d3b1d83c7175ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "luxonis_model.infer(\n",
    "    weights=weights,\n",
    "    view=\"test\"\n",
    ")\n",
    "\n",
    "# NOTE: If you are using Google Colab use this and images will be saved to \"infer_results\" directory\n",
    "# luxonis_model.infer(weights=weights, save_dir=\"infer_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Export and Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained and tested, we want to prepare it for deployment on the device. This preparation consists of 2 steps. First, we want to export the model that was trained with PyTorch to a more general format called ONNX. Then, we want to package this exported model with all the metadata that holds information about the inputs, outputs, and training configuration used. This is called archiving. These steps can be easily done by just one command in LuxonisTrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Loaded checkpoint from                                                            <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">luxonis_lightning.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#937\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">937</span></a>\n",
       "         <span style=\"color: #800080; text-decoration-color: #800080\">/home/jovyan/output/79-blush-viper/min_val_loss/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">cat_dog_detection_model_loss</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>72 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>\n",
       "         17_49.ckpt.                                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Loaded checkpoint from                                                            \u001b]8;id=103749;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\u001b\\\u001b[2mluxonis_lightning.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=649675;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#937\u001b\\\u001b[2m937\u001b[0m\u001b]8;;\u001b\\\n",
       "         \u001b[35m/home/jovyan/output/79-blush-viper/min_val_loss/\u001b[0m\u001b[95mcat_dog_detection_model_loss\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0m72 \u001b[2m                        \u001b[0m\n",
       "         17_49.ckpt.                                                                       \u001b[2m                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> No model executable specified for archiving.                                                   <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">core.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py#716\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">716</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mWARNING \u001b[0m No model executable specified for archiving.                                                   \u001b]8;id=580629;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py\u001b\\\u001b[2mcore.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=640460;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py#716\u001b\\\u001b[2m716\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Exporting model to ONNX<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                     <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">core.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py#718\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">718</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Exporting model to ONNX\u001b[33m...\u001b[0m                                                                     \u001b]8;id=772664;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py\u001b\\\u001b[2mcore.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=753924;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py#718\u001b\\\u001b[2m718\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> No model weights specified. Exporting model without weights.                                   <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">core.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py#335\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">335</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mWARNING \u001b[0m No model weights specified. Exporting model without weights.                                   \u001b]8;id=997791;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py\u001b\\\u001b[2mcore.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=196704;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py#335\u001b\\\u001b[2m335\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Reparametrizing <span style=\"color: #008000; text-decoration-color: #008000\">'EfficientRep'</span>.                                                        <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/nodes/backbones/efficientrep/efficientrep.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">efficientrep.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/nodes/backbones/efficientrep/efficientrep.py#140\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Reparametrizing \u001b[32m'EfficientRep'\u001b[0m.                                                        \u001b]8;id=702483;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/nodes/backbones/efficientrep/efficientrep.py\u001b\\\u001b[2mefficientrep.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=924336;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/nodes/backbones/efficientrep/efficientrep.py#140\u001b\\\u001b[2m140\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Reparametrizing <span style=\"color: #008000; text-decoration-color: #008000\">'RepPANNeck'</span>.                                                           <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/nodes/necks/reppan_neck/reppan_neck.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">reppan_neck.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/nodes/necks/reppan_neck/reppan_neck.py#197\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Reparametrizing \u001b[32m'RepPANNeck'\u001b[0m.                                                           \u001b]8;id=705450;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/nodes/necks/reppan_neck/reppan_neck.py\u001b\\\u001b[2mreppan_neck.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=220863;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/nodes/necks/reppan_neck/reppan_neck.py#197\u001b\\\u001b[2m197\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Model exported to output/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span>-blush-viper/export/cat_dog_detection_model.onnx       <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">luxonis_lightning.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#612\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">612</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Model exported to output/\u001b[1;36m79\u001b[0m-blush-viper/export/cat_dog_detection_model.onnx       \u001b]8;id=405175;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py\u001b\\\u001b[2mluxonis_lightning.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=681665;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/models/luxonis_lightning.py#612\u001b\\\u001b[2m612\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Simplifying ONNX model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                               <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">export_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m Simplifying ONNX model\u001b[33m...\u001b[0m                                                               \u001b]8;id=85338;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py\u001b\\\u001b[2mexport_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=671589;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py#41\u001b\\\u001b[2m41\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> ONNX model saved to output/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span>-blush-viper/export/cat_dog_detection_model.onnx           <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">export_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py#47\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">47</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m ONNX model saved to output/\u001b[1;36m79\u001b[0m-blush-viper/export/cat_dog_detection_model.onnx           \u001b]8;id=69758;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py\u001b\\\u001b[2mexport_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=31773;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py#47\u001b\\\u001b[2m47\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> NN Archive saved to output/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span>-blush-viper/archive/cat_dog_detection_model.onnx.tar.xz          <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">core.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py#793\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">793</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO    \u001b[0m NN Archive saved to output/\u001b[1;36m79\u001b[0m-blush-viper/archive/cat_dog_detection_model.onnx.tar.xz          \u001b]8;id=552679;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py\u001b\\\u001b[2mcore.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=169045;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/core.py#793\u001b\\\u001b[2m793\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Failed to strictly load old weights. The model likely underwent re-parametrization,     <a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">export_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py#27\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27</span></a>\n",
       "         which is a destructive operation. Loading old weights with <span style=\"color: #808000; text-decoration-color: #808000\">strict</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>.                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mERROR   \u001b[0m Failed to strictly load old weights. The model likely underwent re-parametrization,     \u001b]8;id=953426;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py\u001b\\\u001b[2mexport_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=151626;file:///opt/conda/lib/python3.11/site-packages/luxonis_train/core/utils/export_utils.py#27\u001b\\\u001b[2m27\u001b[0m\u001b]8;;\u001b\\\n",
       "         which is a destructive operation. Loading old weights with \u001b[33mstrict\u001b[0m=\u001b[3;91mFalse\u001b[0m.                \u001b[2m                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model archieved to: output/79-blush-viper/archive/cat_dog_detection_model.onnx.tar.xz\n"
     ]
    }
   ],
   "source": [
    "archieve_path = luxonis_model.archive(weights=weights)\n",
    "print(\"Model archieved to:\", archieve_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that two new folders were created in our run directory. One is called `export` and has an ONNX model while the other is called `archive` which has `.tar.xz` file. The tar file is a compressed file which holds aforementioned ONNX model with all the metadata of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the exported model, and the goal is to deploy it to the Luxonis device. The model's specific format depends on the Luxonis device series you have. To simplify the process, we recommend you use our [`HubAI`](https://hub.luxonis.com) platform. You can log in, navigate to the AI section, and click the `+ Add Model` button. \n",
    "\n",
    "<img src=\"./media/first_page.png\" alt=\"first page\" width=\"800\">\n",
    "\n",
    "Once there, you'll want to click `Custom,` and then fill out the form to provide some description of your model. At the bottom, you can upload the actual model files. Since we have already generated an `NNArchive` (our .tar.xz file), please add it here by clicking `Add`. \n",
    "\n",
    "<img src=\"./media/cat_dog_model_desctiption.png\" alt=\"model description\" width=\"400\">\n",
    "\n",
    "Once the model is uploaded, you will see it under `Team's Models`, and when you click it, you can export it for your specific Luxonis device version. \n",
    "\n",
    "<img src=\"./media/cat_dog_convert.png\" alt=\"convert\" width=\"800\">\n",
    "\n",
    "The process might take some time; after it's finished, we can download and use the model with our DepthAI script. We'll use RVC2 in this tutorial, but you can follow the same process for other versions. All that is left to do is create a DepthAI script and deploy the model to the device. We already made such an example below. You need to populate two variables, though:\n",
    "- `ModelSlug`: This is a string representation of your model version based on which DepthAI can download it. You can get it by clicking the `Copy` button next to the `Convert` you used before.\n",
    "- `ApiToken`: Since this model is private to your team, you need a token to access it. To generate the token, we navigate to team settings and click `+ Create API Token`. We then copy and paste it into the script below. \n",
    "\n",
    "<img src=\"./media/cat_dog_model_slug.png\" alt=\"model_slug\" width=\"400\">\n",
    "\n",
    "<img src=\"./media/api_token.png\" alt=\"api_token\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì∑ DepthAI Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SLUG = \"cat-dog-detection-model:model-variant-1\" # TODO: Insert your model slug\n",
    "API_TOKEN = \"insert_your_token_here\" # TODO: Insert your API Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the DepthAI script we need to install it. Also note that this script must be run locally and needs a Luxonis device connected to your machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://artifacts.luxonis.com/artifactory/luxonis-python-release-local/\n",
      "Collecting depthai==3.0.0a6\n",
      "  Downloading https://artifacts.luxonis.com/artifactory/luxonis-python-release-local/depthai/depthai-3.0.0a6-cp311-cp311-macosx_11_0_arm64.whl (69.1 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: depthai\n",
      "Successfully installed depthai-3.0.0a6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --extra-index-url https://artifacts.luxonis.com/artifactory/luxonis-python-release-local/ depthai==3.0.0a6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"DEPTHAI_HUB_API_KEY\"] = API_TOKEN\n",
    "\n",
    "labels = [\"cat\", \"dog\"]\n",
    "\n",
    "with dai.Pipeline() as pipeline:\n",
    "    camera_node = pipeline.create(dai.node.Camera).build()\n",
    "\n",
    "    model = dai.NNModelDescription(MODEL_SLUG)\n",
    "\n",
    "    detection_nn = pipeline.create(dai.node.DetectionNetwork).build(camera_node, model)\n",
    "\n",
    "    frame_queue = detection_nn.passthrough.createOutputQueue()\n",
    "    detection_queue = detection_nn.out.createOutputQueue()\n",
    "\n",
    "    pipeline.start()\n",
    "\n",
    "    while pipeline.isRunning():\n",
    "        frame: np.ndarray = frame_queue.get().getCvFrame()\n",
    "        nn_output: dai.ImgDetections = detection_queue.get()\n",
    "\n",
    "        for detection in nn_output.detections:\n",
    "            xmin, ymin, xmax, ymax = (\n",
    "                detection.xmin,\n",
    "                detection.ymin,\n",
    "                detection.xmax,\n",
    "                detection.ymax,\n",
    "            )\n",
    "\n",
    "            xmin = int(xmin * frame.shape[1])\n",
    "            ymin = int(ymin * frame.shape[0])\n",
    "            xmax = int(xmax * frame.shape[1])\n",
    "            ymax = int(ymax * frame.shape[0])\n",
    "\n",
    "            cv2.rectangle(\n",
    "                frame, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (255, 0, 0), 2\n",
    "            )\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"{detection.confidence * 100:.2f}%\",\n",
    "                (int(xmin) + 10, int(ymin) + 20),\n",
    "                cv2.FONT_HERSHEY_TRIPLEX,\n",
    "                0.5,\n",
    "                255,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                labels[detection.label],\n",
    "                (int(xmin) + 10, int(ymin) + 40),\n",
    "                cv2.FONT_HERSHEY_TRIPLEX,\n",
    "                0.5,\n",
    "                255,\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"Detections\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(\"q\"):\n",
    "            pipeline.stop()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
